{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0caa3d",
   "metadata": {},
   "source": [
    "# Convolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b336e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from scipy.signal import firwin\n",
    "from IPython.display import display, Audio, Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b589b",
   "metadata": {},
   "source": [
    "Convolution can be used as cross-synthesis, a process through which the sonic characteristics of one signal is used to alter the character of another. \n",
    "\n",
    "Mathematically, convolution is defined as\n",
    "$$(f * g)(t) = \\int_{-\\infty}^\\infty f(\\tau) g(t - \\tau) d\\tau$$\n",
    "\n",
    "But, we can think about it \"blending\" two functions of signals. The integral expresses the amount of overlap of one function as its shifted over the other.\n",
    "\n",
    "<img src=\"https://docs.scipy.org/doc/scipy/_images/scipy-signal-convolve-1.png\" alt=\"Image of feedfoward comb filter block diagram\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520675f9",
   "metadata": {},
   "source": [
    "## Reverb\n",
    "\n",
    "We'll start looking at convolution through the lens of convolution reverb. \n",
    "\n",
    "In convolution reverb, we \"combine\" an impulse response of a room with our input signal.\n",
    "\n",
    "The impulse response is the measure of a room's response over time. It is characterized by the sum of filtered and delayed reflections.  \n",
    "\n",
    "An impulse response is created by playing a quick sound, or an impulse, in a space. The impulse is usually a short, percussive sound (a starter pistol, a clapboard / slate, a balloon popping, etc.) but can sometimes be a more sustained sound that moves through the frequency spectrum (e.g., a sine sweep). \n",
    "\n",
    "People record and collect these impulse responses (though researchers also try to predict and model the impulse responses themselves) and they form the basis of many reverb plugins in DAWs. These impulse responses are then used to transform an input signal to recreate the timbre of a particular space or setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233fe39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://audiotech2images.s3.us-east-2.amazonaws.com/IRshortReverb.png\", embed=True, width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c6c0aa",
   "metadata": {},
   "source": [
    "Remember reverb is different than a simple delay or echo.  Reverb is the result of many reflecting sound waves moving through a medium and decaying over time. The reverberation (and impulse response) is determined by size, shape, and materials in the room which determine how sound waves are reflected, absorbed, and diffused.\n",
    "\n",
    "Reverb is made up of the direct sound, early reflections, and late reflections, where\n",
    "- Direct signal -> source to ear\n",
    "- Early reflections -> source to “wall” to ear\n",
    "- Late reflections -> source to “wall” to ”wall” etc\n",
    "\n",
    "When an impulse is produced in a space, the way the space responds to each frequency in that impulse can vary greatly. Some frequencies might be absorbed more than others, some might be reflected more efficiently, and some might cause resonances at specific points in the space. These variations in response are essentially the acoustic signature of the space and are captured in the impulse response. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2efe3e",
   "metadata": {},
   "source": [
    "## Convolution of the frequency spectra\n",
    "\n",
    "When we convolve an impulse response (IR) with another signal, we are multiplying their components in the frequency domain. This ultimately has the effect of applying the frequency-dependent changes of the IR to the other signal, such that the signal takes on the frequency response of the IR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff74e69",
   "metadata": {},
   "source": [
    "Let's listen to an example first. We will take the sound of a (dry) dog bark and convolve it with an impulse response to create a bark with reverb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a6835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8091375c",
   "metadata": {},
   "source": [
    "We'll use the numpy function `convolve` to convolve the two time series. \n",
    "\n",
    "First, we have to normalize the values and convert to floating point due to the nature of scaling problems with convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea12c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce5e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4f178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8e5266d",
   "metadata": {},
   "source": [
    "Outside of reverb, we can also apply convolution to two different audio signals. This is for the cross-synthesis feature of blending two sounds and works well for rhythmic sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7d7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e37585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34824516",
   "metadata": {},
   "source": [
    "Notice that it took much longer to process that convolution than the others.\n",
    "\n",
    "Convolution is very processing-intensive. It takes up a lot of memory and processing time. Let's work through the math to figure out why.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ce144f",
   "metadata": {},
   "source": [
    "Convolution essentially maps the interaction of two functions (f1, f2) over time to a third function (f1 * f2). In our case, \"time\" here will be represented by the incrementation of samples. We understand that each sample number is processed at a different time, T. \n",
    "\n",
    "What we need to do is to multiply every sample value from our input signal to each value of our impulse response. We then add those signals together but shifted in increments of time, T, where T is just one sample.\n",
    "#### Convolution definition:\n",
    "$$(f * g)(t) = \\int_{-\\infty}^\\infty f(\\tau) g(t - \\tau) d\\tau$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb9518c",
   "metadata": {},
   "source": [
    "Let's do this manually.\n",
    "\n",
    "We'll start by two signal vectors f and g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14cb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6e04436",
   "metadata": {},
   "source": [
    "We need to multiply signal g by signal f over time and add at each time position. This looks like sliding signal g across signal f. The result is the output of the convolution at that time position.\n",
    "\n",
    "| 2  | 4  | 3  | 6  |   |   |   |   | Result|\n",
    "|-|-|-|-|-|-|-|-|-|\n",
    "| 1  |   |   |  |  |   |  |   | 2(1) = 2\n",
    "|  5 | 1  |  |   |   |   |   |   | 2(5) + 4(1) = 14\n",
    "|  2 | 5 |  1 |   |   |   |   |   | 2(2) + 4(5) + 3(1) = 27\n",
    "|  3 | 2  | 5  | 1  |   |   |   |   |2(3) + 4(2) + 3(5) + 6(1) = 35\n",
    "|  4 | 3  | 2  | 5  |   |   |   |   |2(4) + 4(3) + 3(2) + 6(5) = 56\n",
    "|   | 4  | 3  | 2  |  |   |   |   |4(4) + 3(3) + 6(2) = 56\n",
    "|   |   | 4  | 3  |  |   |   |   |4(4) + 3(3) + 6(2) = 37\n",
    "|   |   |   | 4  |  |   |   |   |4(4) + 3(3) + 6(2) = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58c7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c365a07",
   "metadata": {},
   "source": [
    "## Convolution and FIR Filters\n",
    "\n",
    "When we perform convolutional reverb, we are essentially treating the reverb as a filter by convolving the impulse with our signal.\n",
    "\n",
    "We can do this with our typical filters in the time domain as long as we know their impulse response.\n",
    "\n",
    "Recall that for an FIR filter, the impulse response is given by the filter coefficients. For example, for the difference equation \n",
    "$$y[n] = x[n] + x[n-1]$$\n",
    "The impulse response is $$h[n] = [1, 1]$$\n",
    "\n",
    "If you remember from Audio Tech I, that is a simple lowpass filter. (moving average filter).\n",
    "\n",
    "We can apply this filter by convolving $h[n]$ with the input signal. $h[n]$ or the impulse response is also called the filter kernel.\n",
    "\n",
    "Note - this only works practically for LTIs (linear time invariant systems) and FIR filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a24666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aca6b5c",
   "metadata": {},
   "source": [
    "Depending on the length of the filter or number of taps (how many samples we are delaying), we can change the filter to resemble our feedforward comb filter.\n",
    "\n",
    "$$y[n] = x[n] + x[n-7]$$\n",
    "\n",
    "$$h[n] = [1, 0, 0, 0, 0, 0 , 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299498b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e4cba8e",
   "metadata": {},
   "source": [
    "We can also define moving average filter by averaging across a specified window. This filter smooths a signal by averaging a number of consecutive samples.\n",
    " \n",
    "$$ y[n] = \\frac{1}{M} \\sum_{k=0}^{M-1} x[n-k]$$\n",
    " \n",
    "This is equivalent to convolving $x[n]$ with a filter $h[n]$ of length $M$:\n",
    "\n",
    "$$ h[n] = \\frac{1}{M}, \\quad 0 \\leq n < M $$\n",
    "\n",
    "This also creates a low pass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce52afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71acc765",
   "metadata": {},
   "source": [
    "### For your curiosity\n",
    "As we've discussed, the problem with filter design is that its frequency response is not directly defined in Hz. It depends on the filter’s impulse response length and shape. \n",
    "\n",
    "To get precise frequency control, we need to connect time-domain parameters (e.g., filter length, shape) to their frequency-domain behavior.\n",
    " \n",
    " To achieve a **specific cutoff frequency** \\( f_c \\) in Hz for a moving average filter, we can determine the required filter length \\( M \\).\n",
    " \n",
    " The relationship between the filter length and cutoff frequency is roughly:\n",
    " \n",
    "$$\n",
    " M = \\frac{0.443 f_s}{f_c}\n",
    "$$\n",
    " \n",
    " - **\\( f_s \\)** is the sampling frequency in Hz.\n",
    " - **\\( f_c \\)** is the desired cutoff frequency in Hz.\n",
    " - **\\( M \\)** is the number of samples in the moving average filter.\n",
    " \n",
    " \n",
    " **Example: Designing a Moving Average Filter with a Specific Cutoff**\n",
    " \n",
    " Suppose we want a **1 kHz low-pass filter** at a sampling rate of **10 kHz**:\n",
    "$$\n",
    " M = \\frac{0.443 \\times 10000}{1000} = 4.43\n",
    "$$\n",
    " \n",
    " Since \\( M \\) must be an integer, we round to \\( M = 4 \\) or \\( M = 5 \\)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76cc177",
   "metadata": {},
   "source": [
    "## Filters and the frequency response\n",
    "\n",
    "In the example above, we can filter the signal by simple convolution or a windowed \"averaging\" of the signal over time. The length of the window will affect how much 'smoothing' of the signal there is and therefore a greater value of $M$ will lead to greater high-frequency removal. (High frequencies change \"too fast\" so are not captured in the averaging)\n",
    "\n",
    "Here our impulse response is a rectangular window and we get a kind of lowpass filter. However, this is a very particular frequency response. A flat line (rectangle window) in the time domain yields a sinc function in the frequency domain.\n",
    "\n",
    "This relationship between a rectangle window and sinc function is very important for constructing ideal filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b68b2d",
   "metadata": {},
   "source": [
    "#### Understanding the Sinc Function in lowpass filtering\n",
    " \n",
    " The sinc function is fundamental in signal processing because it defines the *ideal* low-pass filter in the time domain, meaning it perfectly passes frequencies below a certain cutoff and blocks everything else.\n",
    " \n",
    " The sinc function is given by:\n",
    " \n",
    "\n",
    "$$ \\text{sinc}(x) = \\frac{\\sin(\\pi x)}{\\pi x} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b94e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a25192f",
   "metadata": {},
   "source": [
    "A true sinc function is **infinite**, so we must truncate it in practice. However, the sinc function oscillates, which causes some artifacts when truncated. To create a practical low-pass filter, we **multiply sinc by a window function** (e.g., Hamming window).\n",
    "  \n",
    "A common FIR low-pass filter is the **Hamming-windowed sinc filter**, which avoids the sharp cutoffs of a simple moving average. Essentially we 'smooth the ends' of the filter to avoid these artifacts, much like in fourier applications like the short time fourier transform.\n",
    "\n",
    "Effectively, the filter (window) applies a weighted sum of delayed inputs to shape the output.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88bac64",
   "metadata": {},
   "source": [
    "Let's use a windowed sinc function for our impulse response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f013dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41181396",
   "metadata": {},
   "source": [
    "There is also a numpy function specifically for windowed FIR filters (or the windowed sinc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2013b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efb0234f",
   "metadata": {},
   "source": [
    "### Notes for activity: Implementing convolution from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = f[0]*g[0]\n",
    "out2 = f[0]*g[1] + f[1]*g[0]\n",
    "out3 = f[0]*g[2] + f[1]*g[1] + f[2]*g[0]\n",
    "out4 = f[0]*g[3] + f[1]*g[2] + f[2]*g[1] + f[3]*g[0]\n",
    "\n",
    "out = np.array([out1, out2, out3, out4])\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf485000",
   "metadata": {},
   "source": [
    "We can also think about implementing this going down the f signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g0 = f[0] * g\n",
    "g0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518dd231",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = f[1] * g\n",
    "g1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb69db0",
   "metadata": {},
   "source": [
    "However, we'd need to line them up with time shifts and add down the column.\n",
    "\n",
    "|   |   |   |   |   |   |   |   | |\n",
    "|-|-|-|-|-|-|-|-|-|\n",
    "T3|   |   |   | 6  | 30  | 12  | 18 | 24  |\n",
    "T2|   |   |  3 | 15  | 6  | 9  | 12  |   |\n",
    "T1|   |  4 | 20  | 8  | 12  | 16  |   |   |\n",
    "T0|  2 | 10  | 4  | 6  | 8  |   |   |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408fca0a",
   "metadata": {},
   "source": [
    "Note, the output length of convolution will always be the (length of f + length of g - 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.convolve(f, g)\n",
    "len1 = len(f)+len(g)-1\n",
    "len2 = len(out)\n",
    "len1==len2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266dc6d",
   "metadata": {},
   "source": [
    "Also, note that convolution is commutative. It does not matter the order you convolve $f*g$ or $g*f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c61cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = np.convolve(f, g)\n",
    "out2 = np.convolve(g, f)\n",
    "np.array_equal(out1, out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77494224",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AudioTechII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
